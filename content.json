{"pages":[{"title":"About me","text":"徐奕峰 YiFeng(Eephone) XuA Full-Stack Developer of GIS and Meteo Shenzhen, Canton, China | +86 13510500103sheeyphone@gmail.com | 331659009@qq.comhttps://github.com/sheeyphoneSummaryExperienced Full-Stack Developer with a background in Geographic Information System and 9+ years of experience in producing robust code, containing 6+ years in Meteorology. Proficiency in spatial solutions including spatial data science, applied, algorithms, back-end service, and front-end visualization. Seeking an overseas opportunity to continue growing, hoping in Sydney, Au. Work ExperienceGIS EngineerPing An Insurance (ShenZhen, Canton, China), From 2022.06 to current Working in a team named PingAn Natural Disaster Lab with title front-end Developer. Developed and maintained the Zephyr System, which is a meteorologic system including disaster monitoring and insured alarming, wrote front-end codes in Vue.js, back-end codes in Java and SpringBoot, established bundles in Docker and created a user-friendly interface. Handled the meteorologic data, including vector, raster, structured data and dynamic data, and published it with MapService in different ways. (Dynamic Precipitation Layers and Services, Hail Layers, Blizzard Layers, Flood Map Service etc.) Analyzed requirements and feasibility, and built the solutions. GIS EngineerYama Technology (ShenZhen, Canton, China), From 2017.07 to 2022.05 Dealt with projects from Meteorology Bureau. Led a team of 8 engineers, and finished at least 3 projects per year. Developed and maintained over 20 systems and back-end processes, including the monitoring system, alarming system, city-safety and hazard-defence system, WeChat mini-page and GIS layers producing processes etc. Managed and maintained over 10 servers, including CentOS and Windows Server in different usage. (Data processing, back-end serving, front-end resources, database, CI/CD, local git repository and map services etc.） Analyzed requirements and feasibility, and built the solutions. Handled emergency issues as technical advisor as the bad weather confront. Early JobsSoftware Engineer in Xiangwan Technology (ShenZhen, Canton, China), From 2015.03 to 2017.06 Built an Android App for teaching kids using the Vuforia AR platform and Unity3D Engine. Built another Android App for smart tourism by using Google Cardbox. Merging and syncing the VR video, recorded by six GoPro devices, bunding the spatial path data with it. GIS Engineer in The State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing (ShenZhen, Canton, China), From 2014.08 to 2015.01 Built the visual application for smart tourism with ArcGIS Engine and C# programing language. Handling spatial data using ArcMap and intrinsic tools. Skills Domains Skills Back-end Java, SpringBoot, SpringCloud, Node.js, geoserver, selenium Front-end JavaScript, Vue.js, React.js, Leaflet.js, Rust-wasm Operation Docker, Jenkins, Nexus, Prometheus, Nginx Data Python, PgSQL, PostGIS, MongoDB, Redis Applied ArcGIS, QGIS, uDig, GDAL Others PhotoShop, Axure EducationB.S. Geographic Information System (2010.09 - 2014.06) South China Agricultural University Guangzhou, Canton, China “Everything is related to everything else, but near things are more related than distant things.” – Waldo Tobler","link":"/about/me.html"}],"posts":[{"title":"Introduce how to import GeoJSON data into MongoDB","text":"Outline Get ready for your GeoJSON data Convert GeoJSON data to JsonArray data for importation Use MongoDB command line tool to import data Finally, import the data successfully and find them Tutorial1. Get ready for your GeoJSON data GeoJSON is a format for encoding a variety of geographic data structures. A GeoJSON object may represent a geometry, a feature, or a collection of features. GeoJSON supports the following geometry types: Point, LineString, Polygon, MultiPoint, MultiLineString, MultiPolygon, and GeometryCollection. The codes below demonstrate a simple GeoJSON file, which is constructed with 4-point features. You could copy the text and paste into your text editor and save it with the .geojson suffix, and load the file you saved into a GIS application like QGIS or ArcMap. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182{ &quot;type&quot;: &quot;FeatureCollection&quot;, &quot;name&quot;: &quot;earthquakes&quot;, &quot;crs&quot;: { &quot;type&quot;: &quot;name&quot;, &quot;properties&quot;: { &quot;name&quot;: &quot;urn:ogc:def:crs:OGC:1.3:CRS84&quot; } }, &quot;features&quot;: [ { &quot;type&quot;: &quot;Feature&quot;, &quot;properties&quot;: { &quot;DateTime&quot;: &quot;1970/01/04 17:00:40.20&quot;, &quot;Latitude&quot;: 24.139, &quot;Longitude&quot;: 102.503, &quot;Depth&quot;: 31.0, &quot;Magnitude&quot;: 7.5, &quot;MagType&quot;: &quot;Ms&quot;, &quot;NbStations&quot;: 90, &quot;Gap&quot;: null, &quot;Distance&quot;: null, &quot;RMS&quot;: 0.0, &quot;Source&quot;: &quot;NEI&quot;, &quot;EventID&quot;: 1970010440 }, &quot;geometry&quot;: { &quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [102.503, 24.139] } }, { &quot;type&quot;: &quot;Feature&quot;, &quot;properties&quot;: { &quot;DateTime&quot;: &quot;1970/01/06 05:35:51.80&quot;, &quot;Latitude&quot;: -9.628, &quot;Longitude&quot;: 151.458, &quot;Depth&quot;: 8.0, &quot;Magnitude&quot;: 6.2, &quot;MagType&quot;: &quot;Ms&quot;, &quot;NbStations&quot;: 85, &quot;Gap&quot;: null, &quot;Distance&quot;: null, &quot;RMS&quot;: 0.0, &quot;Source&quot;: &quot;NEI&quot;, &quot;EventID&quot;: 1970010640 }, &quot;geometry&quot;: { &quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [151.458, -9.628] } }, { &quot;type&quot;: &quot;Feature&quot;, &quot;properties&quot;: { &quot;DateTime&quot;: &quot;1970/01/08 17:12:39.10&quot;, &quot;Latitude&quot;: -34.741, &quot;Longitude&quot;: 178.568, &quot;Depth&quot;: 179.0, &quot;Magnitude&quot;: 6.1, &quot;MagType&quot;: &quot;Mb&quot;, &quot;NbStations&quot;: 59, &quot;Gap&quot;: null, &quot;Distance&quot;: null, &quot;RMS&quot;: 0.0, &quot;Source&quot;: &quot;NEI&quot;, &quot;EventID&quot;: 1970010840 }, &quot;geometry&quot;: { &quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [178.568, -34.741] } }, { &quot;type&quot;: &quot;Feature&quot;, &quot;properties&quot;: { &quot;DateTime&quot;: &quot;1970/01/10 12:07:08.60&quot;, &quot;Latitude&quot;: 6.825, &quot;Longitude&quot;: 126.737, &quot;Depth&quot;: 73.0, &quot;Magnitude&quot;: 6.1, &quot;MagType&quot;: &quot;Mb&quot;, &quot;NbStations&quot;: 91, &quot;Gap&quot;: null, &quot;Distance&quot;: null, &quot;RMS&quot;: 0.0, &quot;Source&quot;: &quot;NEI&quot;, &quot;EventID&quot;: 1970011040 }, &quot;geometry&quot;: { &quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [126.737, 6.825] } } ]} 2. Convert GeoJSON data to JsonArray data for importationThe key thing to importing GeoJSON data into Mongodb is the file conversion from GeoJSON to JsonObject or JsonArray. In addition, there are a lot of ways to do so, but, I want to tell you the best way by using a tool called jq. ( jq Official Website here!) When you finish your download, you could do the conversion by using the command below. Importantly, you must put your own configuration text to replace the text between the square brackets and remove the square brackets finally. Then, try it yourself. 1jq --compact-output &quot;.features&quot; '[Your GeoJSON File]' &gt; '[GeoJSON File converted]' 3. Use mongodb command line tool to import dataIn this step, you should check your system environment config and make sure the MongoDB client or command line tools have been installed well firstly. Then, you could use the command below and replace the content between square brackets as you do well in the previous step. 1mongoimport -u '[Your MongoDB User]' --password '[Your Password]' --db '[Database to Import]' -c '[Collection to Import]' --file '[Path to Your GeoJSON File]' --jsonArray '[MongoDB Connection String]' Here is the positive result that tells you which MongoDB has been connected and how many documents have been imported. 12connected to: mongodb://***********4 document(s) imported successfully. 0 document(s) failed to import. 4. Finally, import the data successfully and find themUse MongoDB Client to find or query the data from the collection you have created. And, here is the result. References &amp; DocumentationsGeoJSON Documentationhttps://geojson.org/geojson-spec MongoDB geospatialhttps://www.mongodb.com/docs/manual/geospatial-queries/#std-label-geospatial-geojson jq-tools Offical Websitehttps://stedolan.github.io/jq/","link":"/2023/02/22/p20230222/"},{"title":"Helps you to gain an understanding of the GeoHash Algorithm step by step","text":"Outline What is the GeoHash Algorithm and why do we need it? How did the GeoHash split the world into a hash array The calculating procedure Verify the result Tutorial1. What is the GeoHash Algorithm and why do we need it?Geohash is a geographic location coding algorithm that leads us dealing the location task which is popular in many applications and service like LBS or so on, and make it efficiency. Let’s discuss an application about when you calling a taxi to go somewhere. It’s easy to think that the app service would send a message or request to the nearest driver who could serves you as soon as possible. Generally, you refresh your location with your country, city and geographic coordinates and let the service known where you are. And the taxi driver would also do this process to upload their position. So, the service in background could calculates the distance between you and the drivers, finding the nearest one to contact you. Quite simple, isn’t it? Further, let’s put us hands dirty in the process above and check the efficiency. First, we generate 100,001 coordinates in longitude and latitude. One of these is your position, and the rest of these are the driver’s. I put our Python script below so you could copy it to your own .ipynb file and go ahead. 123456789import numpy as np# Simulate a position as yoursyour_pos = [np.random.uniform(115, 125),np.random.uniform(20, 25)]# Create 100,000 taxicabssize = 10000000drivers_pos = [[np.random.uniform(115, 125),np.random.uniform(20, 25)] for i in range(0,size)] Here, we have prepared the simulation data and be ready for the next step. In this step, we will find out 10 drivers near you. So, let’s do it by the codes below. 12345import math# define a function to calcuate the distance in simply waydef simple_distance(lon_a, lat_a, lon_b, lat_b): return math.sqrt((lon_a - lon_b)**2 + (lat_a - lat_b)**2) 2. How did the GeoHash split the world into a hash array?3. The calculating procedure4. Verify the resultReferences &amp; DocumentationsGeoHash Wikipedia https://en.wikipedia.org/wiki/Geohash GeoHash Explorer https://geohash.softeng.co/","link":"/2023/03/04/p20230304/"},{"title":"A simple way to import raster data into the PostGIS database","text":"Outline Installing the PostGIS Database Enabling the raster extension in PostGIS Preparing or creating the raster data Knowing about the Raster WKB/WKT format Creating the importation-SQL file to execute Tutorial1. Installing the PostGIS DatabaseThe easiest way to install the PostGIS database is using Docker, or you could choose another way to install it. Hence, install the Docker environment and docker-compose plugin on your computer, and here, the hyperlink below is the tutorial and documentation of how to install Docker. Docker Engine installation overview | Docker Documentation Whether the Docker has already installed, you could use docker-compose to run the database by configuring the docker-compose.yml file. The configuration file example is below the paragraph. 12345678910111213141516171819202122version: &quot;3.7&quot;services: pgdb: image: &quot;postgis/postgis:15-master&quot; container_name: pgdb restart: always environment: POSTGRES_DB: gis_data POSTGRES_USER: xyf POSTGRES_PASSWORD: xyf TZ: Asia/Shanghai volumes: - &quot;/data/postgis/data/:/var/lib/postgresql/data/&quot; - &quot;/data/postgis/tmp/:/tmp&quot; ports: - &quot;5432:5432&quot; networks: - &quot;enet&quot;networks: enet: name: &quot;enet&quot; external: true Once you have done it and the PostGIS database has been running well, you could make a connection to the database, using the DBMS application such as DBeaver or GIS application addressed QGIS. 2. Enabling the raster extension in PostGISThere are a few extensions supported by PostGIS spatial engine. The default running configuration shows that 3 of these extensions have been enabled. But it was unfortunate to say the raster extension is not enabled by default way. So we should switch on it by ourselves.The first step is to make your command line jump into the docker container, which is the database container you have created before. 1sudo docker exec -it pgdb /bin/bash After entering the container bash, you could connect to the database by using the command line tool that Postgres offered and named ‘psql’. It’s pretty easy to do. In addition, here are some explanations about the parameters. ‘-U’ is the user and ‘-d’ is the database name. I hope you could find it in the docker-compose configuration file that we have mentioned before. 1psql -U xyf -d gis_data After you finish your connection, I would say ‘Congratulation!’ to you and give you the instruction for the next step. These three SQL commands below will help you to enable the postgis_raster extension, and the gdal_drivers and query the status of the available extensions. You would see the result of your query formed as a table heading the name, default_version and installed_version. So easy, isn’t it? Make sure the installed_version of postgis_raster, yes the column is not NULL. 1234CREATE EXTENSION postgis_raster;SET postgis.gdal_enabled_drivers = 'ENABLE_ALL';SELECT name, default_version,installed_version FROM pg_available_extensions WHERE name LIKE 'postgis%' or name LIKE 'address%'; 3. Preparing or creating the raster dataI’m sure that you are sure that one of the key steps we should do before importing raster data into the database is owing the raster data. Haha, if you don’t have your own raster data. You could create it using QGIS with the tools called Interpolation or so on. Then, export it into the GeoTiff format and copy or move the GeoTiff file you exported to the file path you have configured on docker-compose.yml and go through our next step. Suggestions: DO NOT MAKE A LARGE RASTER DATA OR YOU WOULD CRY ON IT! 4. Knowing about the Raster WKB/WKT formatHow does the PostGIS database store the raster data? It’s a pretty good question. As we know that PostGIS store the vector data with data type ‘geometry_column’ or ‘geom’. And the way to store raster data is familiar with it, demonstrating a new data type called ‘raster’ or ‘rast’. When you make a selection by querying some raster data on a database. You would see the HEX result looks like ‘01000001CDDB….’ and it is the WKB/WKT data format of a raster. About all, the key to importing raster data into the PostGIS database is converting your own raster data into WKB/WKT raster format. You may find out the attributes of Raster WKB/WKT by clicking the link below.WKTRaster/Documentation01 – PostGIS (osgeo.org) 5. Creating the importation-sql file to executeI would say it’s much more convenient to make the conversion by using the script or tool that PostGIS has already done before, named ‘raster2pgsql’. You could find the usage of ‘raster2pgsql’ via the command ‘raster2pgsql’ after we jump into the container in which the database is running on it. We should find out and reach the path where the testing GeoTiff is waiting for us. 1raster2pgsql -s 4326 -I -C /tmp/test.tif nc.test_raster &gt; test.sql We may specify the SRID of our raster in the progress, and the example illustrates the parameter with ‘-s 4326’. You could get the explanations about parameters ‘-I’ and ‘-C’ by yourself. ‘/tmp/test.tif’ is the file path of your GeoTiff file. ‘nc.test_raster’ shows the schema with ‘nc’ and the table name is ‘test_raster’. Finally, the SQL file would be created into the path you running this command and named test.sql. 1234567BEGIN;CREATE TABLE &quot;nc&quot;.&quot;test_raster&quot; (&quot;rid&quot; serial PRIMARY KEY,&quot;rast&quot; raster);INSERT INTO &quot;nc&quot;.&quot;test_raster&quot; (&quot;rast&quot;) VALUES ('010000010019CC5D8DE459B93F14F061B29570B9BFD174763238005C403E7799994DC0374000000000000000000000000000000000E610000029001A004B000000008087C3C0F355F2B1BB1C394014ED2AA4FC3C39409A780778D25E394016FC36C478813940B1FB8EE1B1A339407714E7A8A3C33940FA4674CFBADE3940111B2C9CA4F13940DAE3857478F839402CF180B229EF3940EB724A404CD23940778192020BA0394083A7902BF55......'::raster);CREATE INDEX ON &quot;nc&quot;.&quot;test_raster&quot; USING gist (st_convexhull(&quot;rast&quot;));ANALYZE &quot;nc&quot;.&quot;test_raster&quot;;SELECT AddRasterConstraints('nc','test_raster','rast',TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,FALSE,TRUE,TRUE,TRUE,TRUE,TRUE);END; You could execute this SQL script using DBeaver, and the ‘nc.test_raster’ would be imported into the database, or you visual it by using QGIS, connecting the database and dropping it into the layers panel. That’s all. References &amp; Documentationsraster2pgsql https://postgis.docs.acugis.com/en/latest/components/raster2pgsql/index.html#documentation using_raster_dataman https://postgis.net/docs/using_raster_dataman.html#RT_Raster_Loader docker_hub_postgis https://hub.docker.com/r/postgis/postgis WKTRaster https://trac.osgeo.org/postgis/wiki/WKTRaster/Documentation01","link":"/2023/02/26/p20230226/"},{"title":"A beginner's guide to build a map website in React","text":"PrefaceAs a GIS developer, I will change my role to a WebGIS Front-end developer when I need to build an interactive map to present some geographic data. Due to my latest work, I’m familiar with building it, using the VueJS framework, cause it’s prevalent among Chinese developers. Even though, thinking globally, the React framework holds the most significant proportion of all MVVM-driven and Front-end frameworks. Get Started with ReactIf you are a Front-end Developer, and familiar with other frameworks rather than React. It would be so easy for you to build a React web application after learning React from its official tutorial. So, get your hands dirty, and here we go. React Offical Website https://beta.reactjs.org/ Create a single-page WebApp Create React App is an officially supported way to create single-page React applications. It offers a modern build setup with no configuration. 123npx create-react-app map-on-reactcd map-on-reactyarn start Prepare dependenciesBuild the map componentBuild the layer componentCompose our componentsResult and conclusion","link":"/2023/03/12/p20230312/"},{"title":"Placing the WGS84 image on Mercator web map","text":"Why?Most map images are rendered from WGS84 sources, such as GeoTIFF, NetCDF etc. It means that each pixel of these images is indexing a geo-coordinate position. For example, we suppose a NetCDF file with longitudes(from 110.1 to 120.0, step 0.1), latitudes(from 20.1 to 30.0, step 0.1) and values. So, there are 100*100 values in this file. Each value could be represented by a pixel in the PNG image file. Finally, we get an image with 100*100 pixels. We put this 100*100 pixels PNG image on a web map, such as Leaflet.js. Leaflet.js give us a convenient way to display an image on a map using the ImageOverlay. Below the ImageOverlay, is the tiled layer as TileLayer. Here, I don’t give a lot of explanation about the tiled layer. But the basis you must know is the projected coordinate system addressed as EPSG:3857 or Web Mercator. You can find the official details on epsg.io. Also, a useful feature are listed on the page and I put it below. Area of use: World between 85.06°S and 85.06°N. So, let me list the differences between these two coordinate systems. Coordinate System Alias Area of use EPSG:4326 WGS84 between 90°S and 90°N EPSG:3857 Web Mercator between 85.06°S and 85.06°N How?The 100*100 PNG image we have created before, is based on WGS84. So the area of use is between 90°S and 90°N. If we use the ImageOverlay to display out image and pass the configuration bbox as [[30.0,110.1],[20.1,120.0]]. Probably, the image is not placed at the right position. And how to solve it? It’s so simple! On EPSG:4326 system, each pixel represent an unit of longitude or latitude. Contracting to EPSG:3857, the scale of latitude is different. So, that’s the problem! Back to our image, we should scale the Y axis from 90.0 to 85.06. So, the ratio is 90/85.06 = 1.058076652... and the height of our image should be scaled to 100/(90/85.06) as proximately 94 or 95. Another way to do this is calculate the latitude we pass to the ImageOverlay. Each latitude should be calculated as [lat]/(90/85.06). So the bbox should be [[28.35333,110.1],[18.99673,120.0]]. Finally, we will see the right result.","link":"/2023/08/26/p20230826/"}],"tags":[{"name":"GIS","slug":"GIS","link":"/tags/GIS/"},{"name":"GeoJSON","slug":"GeoJSON","link":"/tags/GeoJSON/"},{"name":"MongoDB","slug":"MongoDB","link":"/tags/MongoDB/"},{"name":"Data importation","slug":"Data-importation","link":"/tags/Data-importation/"},{"name":"Spatial Indexing","slug":"Spatial-Indexing","link":"/tags/Spatial-Indexing/"},{"name":"Spatial Algorithm","slug":"Spatial-Algorithm","link":"/tags/Spatial-Algorithm/"},{"name":"GeoHash","slug":"GeoHash","link":"/tags/GeoHash/"},{"name":"PostGIS","slug":"PostGIS","link":"/tags/PostGIS/"},{"name":"Raster","slug":"Raster","link":"/tags/Raster/"},{"name":"Database","slug":"Database","link":"/tags/Database/"},{"name":"React","slug":"React","link":"/tags/React/"},{"name":"HTML5","slug":"HTML5","link":"/tags/HTML5/"},{"name":"Javascript","slug":"Javascript","link":"/tags/Javascript/"},{"name":"Leaflet","slug":"Leaflet","link":"/tags/Leaflet/"},{"name":"Map","slug":"Map","link":"/tags/Map/"},{"name":"Beginner","slug":"Beginner","link":"/tags/Beginner/"}],"categories":[]}